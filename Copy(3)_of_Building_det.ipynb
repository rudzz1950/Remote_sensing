{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudzz1950/Remote_sensing/blob/main/Copy(3)_of_Building_det.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Architecture\n"
      ],
      "metadata": {
        "id": "mwqcrutT_ohz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie5uLDH4uzAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd1c2d3-c5da-42c6-cf22-0cb4f9207eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 51782, done.\u001b[K\n",
            "remote: Counting objects: 100% (924/924), done.\u001b[K\n",
            "remote: Compressing objects: 100% (634/634), done.\u001b[K\n",
            "remote: Total 51782 (delta 669), reused 292 (delta 290), pack-reused 50858 (from 3)\u001b[K\n",
            "Receiving objects: 100% (51782/51782), 30.21 MiB | 10.96 MiB/s, done.\n",
            "Resolving deltas: 100% (37994/37994), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/ultralytics.git  # Clone YOLOv8 repo\n",
        "!cd ultralytics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Input image\n",
        "https://drive.google.com/file/d/1HFFAzC9S3yl8BtZ0WZGwt5h_HuK8OHdx/view?usp=sharing\n",
        "\n",
        "2. Output image\n",
        "https://drive.google.com/file/d/1fYcPXh60cLzIE1CLh0k6yNe89TAR7Ja6/view?usp=sharing"
      ],
      "metadata": {
        "id": "6I9Ljbdu_ZVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "id": "rNlO0H43MU3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bbd842c-a110-496f-d852-5bfa06579a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.91-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.91-py3-none-any.whl (949 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.2/949.2 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.91 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "ECieZUKN-i8k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5733d6f-422e-44a4-bd9e-f015c9135415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Setup complete. Using torch 2.6.0+cu124 on CUDA\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 49.7M/49.7M [00:01<00:00, 42.1MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YOLOv8 model loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Check PyTorch and CUDA\n",
        "device = \"CUDA\" if torch.cuda.is_available() else \"CPU\"\n",
        "print(f\"Setup complete. Using torch {torch.__version__} on {device}\")\n",
        "\n",
        "# Load a YOLOv8 model to test\n",
        "model = YOLO(\"yolov8m.pt\")  # Load the nano model\n",
        "print(\"YOLOv8 model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install earthengine-api\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlHM44MXdaXG",
        "outputId": "b8e1bed5-edb7-4cde-efaf-2a04a72740d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: earthengine-api in /usr/local/lib/python3.11/dist-packages (1.5.6)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.19.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.160.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (0.2.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (0.22.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from earthengine-api) (2.32.3)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (4.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->earthengine-api) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->earthengine-api) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1dev,>=0.9.2->earthengine-api) (3.2.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->earthengine-api) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->earthengine-api) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->earthengine-api) (1.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->earthengine-api) (2025.1.31)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.69.1)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (4.25.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Authenticate your account (you only need to do this once)\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize with a project ID (replace with your project)\n",
        "ee.Initialize(project='vitproject2025')  # Replace this!\n"
      ],
      "metadata": {
        "id": "KFx6VGW0dbO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='vitproject2025')  # Replace with your actual project ID\n",
        "\n",
        "# Load the FeatureCollection with a limit\n",
        "ind = ee.FeatureCollection(\"projects/sat-io/open-datasets/VIDA_COMBINED/IND\").limit(5000)\n",
        "\n",
        "print(ind.size().getInfo())  # Print the number of elements\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPQjSF59dkd5",
        "outputId": "e8826149-f153-44a3-b1a1-009bd423c10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_location = \"projects/sat-io/open-datasets/VIDA_COMBINED/IND\"\n",
        "print(\"Checking dataset folder:\", os.path.exists(dataset_location))\n",
        "print(\"Contents:\", os.listdir(dataset_location) if os.path.exists(dataset_location) else \"Folder missing!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogypb47biQT4",
        "outputId": "cd30af26-ea91-4c0b-8ae8-1a28e1c10066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking dataset folder: False\n",
            "Contents: Folder missing!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the base path for YOLOv8 dataset\n",
        "dataset = ee.FeatureCollection(\"users/sat-io/awesome-gee-catalog-examples\")  # Adjust to match your dataset (e.g., 'house_alloc-17')\n",
        "\n",
        "# Define all required subdirectories\n",
        "subdirs = [\n",
        "    'train/images',\n",
        "    'train/labels',\n",
        "    'valid/images',\n",
        "    'valid/labels',\n",
        "    'test/images',\n",
        "    'test/labels'\n",
        "]\n",
        "\n",
        "# Create directories\n",
        "try:\n",
        "    for subdir in subdirs:\n",
        "        dir_path = os.path.join(dataset_location, subdir)\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "    print(\"Directories for YOLOv8 dataset created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to create directories: {e}\")\n",
        "\n",
        "# Verify the structure\n",
        "print(\"Created directory structure:\")\n",
        "for subdir in subdirs:\n",
        "    print(f\"- {os.path.join(dataset_location, subdir)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiqfSv9_NMTT",
        "outputId": "4e178018-a9ec-4308-ec6c-2861ac05eb82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directories for YOLOv8 dataset created successfully!\n",
            "Created directory structure:\n",
            "- projects/sat-io/open-datasets/VIDA_COMBINED/IND/train/images\n",
            "- projects/sat-io/open-datasets/VIDA_COMBINED/IND/train/labels\n",
            "- projects/sat-io/open-datasets/VIDA_COMBINED/IND/valid/images\n",
            "- projects/sat-io/open-datasets/VIDA_COMBINED/IND/valid/labels\n",
            "- projects/sat-io/open-datasets/VIDA_COMBINED/IND/test/images\n",
            "- projects/sat-io/open-datasets/VIDA_COMBINED/IND/test/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=ind,\n",
        "    description='India_FeatureCollection',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "task.start()"
      ],
      "metadata": {
        "id": "Ns48c4eHdnun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install folium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XewCeiNvl1ql",
        "outputId": "51db45ac-1067-4e1e-a95a-40a57b2609f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: folium in /usr/local/lib/python3.11/dist-packages (0.19.5)\n",
            "Requirement already satisfied: branca>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from folium) (0.8.1)\n",
            "Requirement already satisfied: jinja2>=2.9 in /usr/local/lib/python3.11/dist-packages (from folium) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from folium) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from folium) (2.32.3)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium) (2025.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=2.9->folium) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->folium) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset = dataset.filter(ee.Filter.eq('property_name', 'property_value'))"
      ],
      "metadata": {
        "id": "tFg0dQHjNdBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "2VlX-RKzN4It"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ3DmmGQztJj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "outputId": "d54ab129-27c3-4c56-d733-c715b8fb6f67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<folium.folium.Map at 0x7e4e58bc0910>"
            ],
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
              "&lt;html&gt;\n",
              "&lt;head&gt;\n",
              "    \n",
              "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
              "    \n",
              "        &lt;script&gt;\n",
              "            L_NO_TOUCH = false;\n",
              "            L_DISABLE_3D = false;\n",
              "        &lt;/script&gt;\n",
              "    \n",
              "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
              "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
              "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
              "    \n",
              "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
              "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
              "            &lt;style&gt;\n",
              "                #map_ccda49d83534f904b3d8a60cc4078e30 {\n",
              "                    position: relative;\n",
              "                    width: 100.0%;\n",
              "                    height: 100.0%;\n",
              "                    left: 0.0%;\n",
              "                    top: 0.0%;\n",
              "                }\n",
              "                .leaflet-container { font-size: 1rem; }\n",
              "            &lt;/style&gt;\n",
              "        \n",
              "&lt;/head&gt;\n",
              "&lt;body&gt;\n",
              "    \n",
              "    \n",
              "            &lt;div class=&quot;folium-map&quot; id=&quot;map_ccda49d83534f904b3d8a60cc4078e30&quot; &gt;&lt;/div&gt;\n",
              "        \n",
              "&lt;/body&gt;\n",
              "&lt;script&gt;\n",
              "    \n",
              "    \n",
              "            var map_ccda49d83534f904b3d8a60cc4078e30 = L.map(\n",
              "                &quot;map_ccda49d83534f904b3d8a60cc4078e30&quot;,\n",
              "                {\n",
              "                    center: [20.0, 78.0],\n",
              "                    crs: L.CRS.EPSG3857,\n",
              "                    ...{\n",
              "  &quot;zoom&quot;: 5,\n",
              "  &quot;zoomControl&quot;: true,\n",
              "  &quot;preferCanvas&quot;: false,\n",
              "}\n",
              "\n",
              "                }\n",
              "            );\n",
              "\n",
              "            \n",
              "\n",
              "        \n",
              "    \n",
              "            var tile_layer_b249d940f8907436ba2da41b8715149c = L.tileLayer(\n",
              "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
              "                {\n",
              "  &quot;minZoom&quot;: 0,\n",
              "  &quot;maxZoom&quot;: 19,\n",
              "  &quot;maxNativeZoom&quot;: 19,\n",
              "  &quot;noWrap&quot;: false,\n",
              "  &quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;,\n",
              "  &quot;subdomains&quot;: &quot;abc&quot;,\n",
              "  &quot;detectRetina&quot;: false,\n",
              "  &quot;tms&quot;: false,\n",
              "  &quot;opacity&quot;: 1,\n",
              "}\n",
              "\n",
              "            );\n",
              "        \n",
              "    \n",
              "            tile_layer_b249d940f8907436ba2da41b8715149c.addTo(map_ccda49d83534f904b3d8a60cc4078e30);\n",
              "        \n",
              "&lt;/script&gt;\n",
              "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Export started! Check Google Drive for the file when complete.\n"
          ]
        }
      ],
      "source": [
        "# Fix locale encoding\n",
        "#import locale\n",
        "#locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "# Your original code\n",
        "#dataset_location = dataset.location\n",
        "#%cat {dataset_location}/data.yaml\n",
        "\n",
        "# This is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "#dataset_location = dataset.location\n",
        "#%cat {dataset_location}/data.yaml\n",
        "\n",
        "\n",
        "# Authenticate and initialize Earth Engine\n",
        "# Add a layer to the map, using Map.addLayer:\n",
        "import folium  # If you haven't already installed it\n",
        "import ee\n",
        "\n",
        "# Initialize Folium map\n",
        "map = folium.Map(location=[20, 78], zoom_start=5)  # Adjust location/zoom as needed\n",
        "\n",
        "# Add dataset layer (GEE datasets need to be visualized differently)\n",
        "dataset = ee.FeatureCollection(\"projects/sat-io/open-datasets/VIDA_COMBINED/IND\")\n",
        "\n",
        "# Display map (this works in a Jupyter Notebook)\n",
        "display(map)\n",
        "\n",
        "# Export dataset to Google Drive\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=dataset,\n",
        "    description='awesome-gee-catalog-examples-export',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "task.start()  # This starts the export process.\n",
        "\n",
        "print(\"Export started! Check Google Drive for the file when complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # YAML file path\n",
        "# yaml_path = os.path.join(dataset_location, 'data.yaml').replace(\"\\\\\", \"/\")\n",
        "\n",
        "# # Check if the YAML file exists\n",
        "# if os.path.exists(yaml_path):\n",
        "#     with open(yaml_path, 'r') as f:\n",
        "#         data = yaml.safe_load(f)\n",
        "# else:\n",
        "#     print(\"YAML file not found! Creating a new one...\")\n",
        "#     data = {}\n",
        "\n",
        "# # Fix relative paths\n",
        "# data['train'] = 'train/images'\n",
        "# data['val'] = 'valid/images'\n",
        "# data['test'] = 'test/images'\n",
        "# data['nc'] = 1  # Number of classes (update if needed)\n",
        "# data['names'] = ['tree']  # Class names (update accordingly)\n",
        "\n",
        "# # Write back to YAML\n",
        "# with open(yaml_path, 'w') as f:\n",
        "#     yaml.safe_dump(data, f)\n",
        "\n",
        "# # print(\"YAML file created/updated successfully!\")\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "# YAML file path\n",
        "yaml_path = os.path.join(dataset_location, 'data.yaml').replace(\"\\\\\", \"/\")\n",
        "\n",
        "# Check if the YAML file exists and is not empty\n",
        "if os.path.exists(yaml_path) and os.path.getsize(yaml_path) > 0:\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        data = yaml.safe_load(f)\n",
        "    if data is None:  # Handle case where file is empty or contains invalid YAML\n",
        "        data = {}\n",
        "else:\n",
        "    print(\"YAML file not found or empty! Creating a new one...\")\n",
        "    data = {}\n",
        "\n",
        "# Fix relative paths\n",
        "data['train'] = 'train/images'\n",
        "data['val'] = 'valid/images'\n",
        "data['test'] = 'test/images'\n",
        "data['nc'] = 1  # Number of classes (update if needed)\n",
        "data['names'] = ['tree']  # Class names (update accordingly)\n",
        "\n",
        "# Write back to YAML\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.safe_dump(data, f)\n",
        "\n",
        "print(\"YAML file created/updated successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_SMDTiAi0HY",
        "outputId": "c52889ff-69cc-4c63-972b-10c6bd72e914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YAML file not found or empty! Creating a new one...\n",
            "YAML file created/updated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOPn9wjOAwwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952666d1-d504-452e-92ce-88281fbaad1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Earth Engine dataset export started. Check Google Drive for the CSV file.\n",
            "Directories for YOLOv8 dataset created successfully!\n",
            "Created directory structure:\n",
            "- /content/earth-engine-dataset/train/images\n",
            "- /content/earth-engine-dataset/train/labels\n",
            "- /content/earth-engine-dataset/valid/images\n",
            "- /content/earth-engine-dataset/valid/labels\n",
            "- /content/earth-engine-dataset/test/images\n",
            "- /content/earth-engine-dataset/test/labels\n",
            "YAML file updated successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import yaml\n",
        "import ee\n",
        "\n",
        "# Authenticate and initialize Google Earth Engine\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='vitproject2025')  # Replace with your actual project ID\n",
        "\n",
        "# Define dataset from Google Earth Engine\n",
        "dataset = ee.FeatureCollection(\"projects/sat-io/open-datasets/VIDA_COMBINED/IND\")\n",
        "\n",
        "# Export dataset to Google Drive\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=dataset,\n",
        "    description='earth-engine-dataset-export',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "task.start()\n",
        "print(\"Google Earth Engine dataset export started. Check Google Drive for the CSV file.\")\n",
        "\n",
        "# Define the base path for YOLOv8 dataset\n",
        "base_path = '/content/earth-engine-dataset'  # Adjust for GEE dataset\n",
        "\n",
        "# Define all required subdirectories\n",
        "subdirs = [\n",
        "    'train/images',\n",
        "    'train/labels',\n",
        "    'valid/images',\n",
        "    'valid/labels',\n",
        "    'test/images',\n",
        "    'test/labels'\n",
        "]\n",
        "\n",
        "# Create directories\n",
        "try:\n",
        "    for subdir in subdirs:\n",
        "        dir_path = os.path.join(base_path, subdir)\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "    print(\"Directories for YOLOv8 dataset created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to create directories: {e}\")\n",
        "\n",
        "# Verify the structure\n",
        "print(\"Created directory structure:\")\n",
        "for subdir in subdirs:\n",
        "    print(f\"- {os.path.join(base_path, subdir)}\")\n",
        "\n",
        "# YAML file path\n",
        "yaml_path = os.path.join(dataset_location, 'data.yaml').replace(\"\\\\\", \"/\")\n",
        "\n",
        "# Read and update the YAML\n",
        "if os.path.exists(yaml_path):\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        data = yaml.safe_load(f)\n",
        "\n",
        "    # Fix relative paths\n",
        "    data['train'] = 'train/images'\n",
        "    data['val'] = 'valid/images'\n",
        "    data['test'] = 'test/images'\n",
        "\n",
        "    # Write back\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.safe_dump(data, f)\n",
        "\n",
        "    print(\"YAML file updated successfully!\")\n",
        "else:\n",
        "    print(\"YAML file not found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = r\"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/models/v8\"\n",
        "if os.path.exists(path):\n",
        "    print(os.listdir(path))\n",
        "else:\n",
        "    print(\"Path does not exist.\")"
      ],
      "metadata": {
        "id": "b5g3gkf7T21k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c05f531-c83f-4d77-9c37-b4027018ad4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['yolov8.yaml', 'yolov8-cls-resnet101.yaml', 'yolov8-ghost.yaml', 'yolov8-cls-resnet50.yaml', 'yolov8-cls.yaml', 'yolov8-ghost-p2.yaml', 'yolov8-worldv2.yaml', 'yolov8-world.yaml', 'yolov8-p2.yaml', 'yolov8-seg.yaml', 'yolov8-p6.yaml', 'yolov8-rtdetr.yaml', 'yolov8-obb.yaml', 'yolov8-pose-p6.yaml', 'yolov8-pose.yaml', 'yolov8-ghost-p6.yaml', 'yolov8-seg-p6.yaml']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rvt5wilnDyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cba6e9fc-5c28-48a8-8c19-59b9abd84937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Ultralytics 🚀 AGPL-3.0 License - https://ultralytics.com/license\n",
            "\n",
            "# Ultralytics YOLOv8 object detection model with P3/8 - P5/32 outputs\n",
            "# Model docs: https://docs.ultralytics.com/models/yolov8\n",
            "# Task docs: https://docs.ultralytics.com/tasks/detect\n",
            "\n",
            "# Parameters\n",
            "nc: 80 # number of classes\n",
            "scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'\n",
            "  # [depth, width, max_channels]\n",
            "  n: [0.33, 0.25, 1024] # YOLOv8n summary: 129 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPS\n",
            "  s: [0.33, 0.50, 1024] # YOLOv8s summary: 129 layers, 11166560 parameters, 11166544 gradients, 28.8 GFLOPS\n",
            "  m: [0.67, 0.75, 768] # YOLOv8m summary: 169 layers, 25902640 parameters, 25902624 gradients, 79.3 GFLOPS\n",
            "  l: [1.00, 1.00, 512] # YOLOv8l summary: 209 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPS\n",
            "  x: [1.00, 1.25, 512] # YOLOv8x summary: 209 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPS\n",
            "\n",
            "# YOLOv8.0n backbone\n",
            "backbone:\n",
            "  # [from, repeats, module, args]\n",
            "  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\n",
            "  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\n",
            "  - [-1, 3, C2f, [128, True]]\n",
            "  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8\n",
            "  - [-1, 6, C2f, [256, True]]\n",
            "  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16\n",
            "  - [-1, 6, C2f, [512, True]]\n",
            "  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\n",
            "  - [-1, 3, C2f, [1024, True]]\n",
            "  - [-1, 1, SPPF, [1024, 5]] # 9\n",
            "\n",
            "# YOLOv8.0n head\n",
            "head:\n",
            "  - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n",
            "  - [[-1, 6], 1, Concat, [1]] # cat backbone P4\n",
            "  - [-1, 3, C2f, [512]] # 12\n",
            "\n",
            "  - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n",
            "  - [[-1, 4], 1, Concat, [1]] # cat backbone P3\n",
            "  - [-1, 3, C2f, [256]] # 15 (P3/8-small)\n",
            "\n",
            "  - [-1, 1, Conv, [256, 3, 2]]\n",
            "  - [[-1, 12], 1, Concat, [1]] # cat head P4\n",
            "  - [-1, 3, C2f, [512]] # 18 (P4/16-medium)\n",
            "\n",
            "  - [-1, 1, Conv, [512, 3, 2]]\n",
            "  - [[-1, 9], 1, Concat, [1]] # cat head P5\n",
            "  - [-1, 3, C2f, [1024]] # 21 (P5/32-large)\n",
            "\n",
            "  - [[15, 18, 21], 1, Detect, [nc]] # Detect(P3, P4, P5)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # This is the model configuration we will use for our tutorial\n",
        "# %cat /content/ultralytics/ultralytics/cfg/models/v8/yolov8-seg.yaml\n",
        "import os\n",
        "# Path to the YOLOv8 model configuration\n",
        "yaml_path = r\"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/models/v8/yolov8.yaml\"\n",
        "\n",
        "# Check if the file exists before reading\n",
        "if os.path.exists(yaml_path):\n",
        "    with open(yaml_path, \"r\") as file:\n",
        "        print(file.read())\n",
        "else:\n",
        "    print(\"File not found:\", yaml_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t14hhyqdmw6O"
      },
      "outputs": [],
      "source": [
        "# Register the custom writetemplate magic\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDxebz13RdRA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa338942-bc10-476c-83b5-be76118690cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config file saved at /content/yolov8m-custom.yaml\n"
          ]
        }
      ],
      "source": [
        "# Set number of classes\n",
        "num_classes = 1  # For 'Houses' from house_alloc-17\n",
        "\n",
        "# Write YOLOv8m custom config using Python file I/O\n",
        "config_text = f\"\"\"# YOLOv8 medium custom config\n",
        "nc: {num_classes}  # Number of classes (1 for Houses)\n",
        "depth_multiple: 0.67  # Model depth multiple (medium scale)\n",
        "width_multiple: 0.75  # Layer channel multiple (medium scale)\n",
        "\n",
        "# Backbone\n",
        "backbone:\n",
        "  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2\n",
        "  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4\n",
        "  - [-1, 3, C2f, [128, True]]   # 2\n",
        "  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8\n",
        "  - [-1, 6, C2f, [256, True]]   # 4\n",
        "  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16\n",
        "  - [-1, 6, C2f, [512, True]]   # 6\n",
        "  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\n",
        "  - [-1, 3, C2f, [1024, True]]  # 8\n",
        "  - [-1, 1, SPPF, [1024, 5]]    # 9 (SPP block)\n",
        "\n",
        "# Head\n",
        "head:\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]  # 10\n",
        "  - [[-1, 6], 1, Concat, [1]]  # 11 cat backbone P4\n",
        "  - [-1, 3, C2f, [512, True]]   # 12\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]  # 13\n",
        "  - [[-1, 4], 1, Concat, [1]]  # 14 cat backbone P3\n",
        "  - [-1, 3, C2f, [256, True]]   # 15 (P3/8-small)\n",
        "  - [-1, 1, Conv, [256, 3, 2]]  # 16\n",
        "  - [[-1, 12], 1, Concat, [1]]  # 17 cat head P4\n",
        "  - [-1, 3, C2f, [512, True]]   # 18 (P4/16-medium)\n",
        "  - [-1, 1, Conv, [512, 3, 2]]  # 19\n",
        "  - [[-1, 9], 1, Concat, [1]]  # 20 cat head P5\n",
        "  - [-1, 3, C2f, [1024, True]]  # 21 (P5/32-large)\n",
        "  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)\n",
        "\"\"\"\n",
        "\n",
        "# Save the config file\n",
        "config_path = \"/content/yolov8m-custom.yaml\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    f.write(config_text)\n",
        "\n",
        "print(f\"Config file saved at {config_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSPQthWMMzjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325b5b84-940b-4124-deff-dd52049384cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# # Update the Ultralytics repo for YOLOv8\n",
        "# !cd /content/ultralytics && git pull\n",
        "\n",
        "import os\n",
        "\n",
        "repo_path = r\"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\"\n",
        "\n",
        "os.system(f'cd /d \"{repo_path}\" && git pull')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_location)"
      ],
      "metadata": {
        "id": "O4QBS5ZOX0jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1736ed7f-f2c3-4da9-9f07-8b1649fd210b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "projects/sat-io/open-datasets/VIDA_COMBINED/IND\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
      ],
      "metadata": {
        "id": "vjCSEw1s0Pua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3643f25-be60-4381-d702-09a6f581c275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_location = \"projects/sat-io/open-datasets/VIDA_COMBINED/IND\" # points to /content/earth-engine-dataset"
      ],
      "metadata": {
        "id": "56kAYQjE4Gzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "outputId": "9b620da2-348e-4971-d5c1-96b363d41a2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 391/475 items from pretrained weights\n",
            "Ultralytics 8.3.91 🚀 Python-3.11.11 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m-custom.yaml, data=projects/sat-io/open-datasets/VIDA_COMBINED/IND/data.yaml, epochs=5, time=None, patience=2, batch=16, imgsz=640, save=True, save_period=-1, cache=disk, device=0, workers=4, project=None, name=yolov8m_results_802, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0005, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/yolov8m_results_802\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Dataset 'projects/sat-io/open-datasets/VIDA_COMBINED/IND/data.yaml' error ❌ \nDataset 'projects/sat-io/open-datasets/VIDA_COMBINED/IND/data.yaml' images not found ⚠️, missing path '/content/datasets/projects/sat-io/open-datasets/VIDA_COMBINED/IND/valid/images'\nNote dataset download directory is '/content/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    573\u001b[0m             }:\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_det_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"yaml_file\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\nNote dataset download directory is '{DATASETS_DIR}'. You can update this in '{SETTINGS_FILE}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: \nDataset 'projects/sat-io/open-datasets/VIDA_COMBINED/IND/data.yaml' images not found ⚠️, missing path '/content/datasets/projects/sat-io/open-datasets/VIDA_COMBINED/IND/valid/images'\nNote dataset download directory is '/content/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_model_file_from_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# avoid auto-downloading dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yaml_file\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset '{clean_url(self.args.data)}' error ❌ {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset 'projects/sat-io/open-datasets/VIDA_COMBINED/IND/data.yaml' error ❌ \nDataset 'projects/sat-io/open-datasets/VIDA_COMBINED/IND/data.yaml' images not found ⚠️, missing path '/content/datasets/projects/sat-io/open-datasets/VIDA_COMBINED/IND/valid/images'\nNote dataset download directory is '/content/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Define the base path for YOLOv8 dataset\n",
        "#base_path = '/content/earth-engine-dataset'  # Adjust for GEE dataset\n",
        "\n",
        "# Define the path to your data.yaml file\n",
        "#data_yaml_path = os.path.join(base_path, 'data.yaml')\n",
        "\n",
        "# Load pretrained YOLOv8n model\n",
        "model = YOLO(\"yolov8m-custom.yaml\").load(\"yolov8m.pt\")  # Load with pre-trained weights\n",
        "\n",
        "# Start with pretrained weights for better performance\n",
        "\n",
        "# Train the model with optimized parameters\n",
        "model.train(\n",
        "    data=f\"{dataset_location}/data.yaml\",  # Path to your dataset config\n",
        "    epochs=5,                         # Train for 100 epochs to ensure convergence\n",
        "    imgsz=640,                          # Larger image size for better detection\n",
        "    batch=16,                           # Batch size suitable for Tesla T4 GPU\n",
        "    patience=2,                        # Early stopping after 5 epochs of no improvement\n",
        "    cache=\"disk\",                       # Use disk caching for deterministic results\n",
        "    device=0,                           # Use GPU (Tesla T4, CUDA:0)\n",
        "    workers=4,                          # Number of data loader workers\n",
        "    pretrained=True,                    # Explicitly use pretrained weights\n",
        "    lr0=0.0005,                         # Lower initial learning rate for stability\n",
        "    mosaic=1.0,\n",
        "    augment=True,                       # Enable data augmentation\n",
        "    name=\"yolov8m_results_80\",\n",
        ")\n",
        "\n",
        "# Optional: Validate the best model after training\n",
        "model.val()  # Runs validation on the best saved weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "img_path = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "print(\"Using file:\", img_path)\n"
      ],
      "metadata": {
        "id": "ALwqEUEhVaeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load TIF image using PIL\n",
        "image = Image.open(img_path).convert(\"RGB\")  # Convert to RGB\n",
        "\n",
        "# Convert to numpy array (YOLO expects numpy format)\n",
        "image_np = np.array(image)\n",
        "\n",
        "# Load trained YOLO model\n",
        "model = YOLO(\"runs/detect/yolov8m_results_80/weights/best.pt\")\n",
        "\n",
        "# Run inference\n",
        "results = model(image_np)\n",
        "\n",
        "# Define output directory inside Colab\n",
        "output_dir = \"/content/output\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create folder if it doesn't exist\n",
        "\n",
        "# Extract original filename without extension\n",
        "base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "output_path = os.path.join(output_dir, f\"{base_name}_output.jpg\")\n",
        "\n",
        "# Display and save results\n",
        "for r in results:\n",
        "    im_array = r.plot(labels=False)  # Get the result image\n",
        "\n",
        "    # Convert array to PIL Image\n",
        "    result_image = Image.fromarray(im_array)\n",
        "\n",
        "    # Save with quality settings (JPEG format)\n",
        "    result_image.save(output_path, format=\"JPEG\", quality=95)\n",
        "\n",
        "    # Show the processed image\n",
        "    plt.imshow(result_image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Result saved at {output_path}\")\n",
        "\n",
        "# Download the image to your local machine\n",
        "files.download(output_path)\n"
      ],
      "metadata": {
        "id": "Ab-PK1fZXfZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Metrics"
      ],
      "metadata": {
        "id": "O7gjjJlVfeXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Path to your image file\n",
        "img_path1 = '/content/runs/detect/yolov8m_results_80/results.png'\n",
        "\n",
        "# Display the image\n",
        "Image(filename=img_path1)\n",
        "\n"
      ],
      "metadata": {
        "id": "IfvOD3W6zczU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVs_4zEeVbF"
      },
      "source": [
        "# Evaluate Custom YOLOv8 Detector Performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov8s_results_80`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
        "\n",
        "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOy5KI2ncnWd"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SyOWS80qR32"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}