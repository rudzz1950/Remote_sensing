{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudzz1950/Remote_sensing/blob/main/Anirudh_edit(1_1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Architecture\n"
      ],
      "metadata": {
        "id": "mwqcrutT_ohz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie5uLDH4uzAp"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/ultralytics.git  # Clone YOLOv8 repo\n",
        "!cd ultralytics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Input image\n",
        "https://drive.google.com/file/d/1HFFAzC9S3yl8BtZ0WZGwt5h_HuK8OHdx/view?usp=sharing\n",
        "\n",
        "2. Output image\n",
        "https://drive.google.com/file/d/1fYcPXh60cLzIE1CLh0k6yNe89TAR7Ja6/view?usp=sharing"
      ],
      "metadata": {
        "id": "6I9Ljbdu_ZVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "id": "rNlO0H43MU3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "print(ultralytics.__path__)\n"
      ],
      "metadata": {
        "id": "BpLvaMsF1SQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "ECieZUKN-i8k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Check PyTorch and CUDA\n",
        "device = \"CUDA\" if torch.cuda.is_available() else \"CPU\"\n",
        "print(f\"Setup complete. Using torch {torch.__version__} on {device}\")\n",
        "\n",
        "# Load a YOLOv8 model to test\n",
        "model = YOLO(\"yolov8m.pt\")  # Load the nano model\n",
        "print(\"YOLOv8 model loaded successfully!\")\n",
        "\n",
        "# From (original detection model):\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "\n",
        "# Change to (segmentation model):\n",
        "model = YOLO(\"yolov8m-seg.pt\")  # <--- Add '-seg' for segmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install earthengine-api\n"
      ],
      "metadata": {
        "id": "AlHM44MXdaXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Authenticate your account (you only need to do this once)\n",
        "ee.Authenticate()\n",
        "\n",
        "# Initialize with a project ID (replace with your project)\n",
        "ee.Initialize(project='vitproject2025')  # Replace this!\n"
      ],
      "metadata": {
        "id": "KFx6VGW0dbO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='vitproject2025')  # Replace with your actual project ID\n",
        "\n",
        "# Load the FeatureCollection with a limit\n",
        "ind = ee.FeatureCollection(\"projects/sat-io/open-datasets/VIDA_COMBINED/IND\").limit(5000)\n",
        "\n",
        "print(ind.size().getInfo())  # Print the number of elements\n"
      ],
      "metadata": {
        "id": "cPQjSF59dkd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install folium"
      ],
      "metadata": {
        "id": "XewCeiNvl1ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "\n",
        "# Initialize Earth Engine\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='vitproject2025')\n",
        "\n",
        "# Access the dataset through Earth Engine API\n",
        "dataset = ee.FeatureCollection(\"projects/sat-io/open-datasets/VIDA_COMBINED/IND\")\n",
        "\n",
        "# Get dataset information\n",
        "print(\"Number of features:\", dataset.size().getInfo())\n",
        "print(\"First 5 features:\", dataset.limit(5).getInfo())\n"
      ],
      "metadata": {
        "id": "Ogypb47biQT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export to Google Drive\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=dataset,\n",
        "    description='IND_Export',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "task.start()\n",
        "\n",
        "# Then check your Google Drive for:\n",
        "# /MyDrive/IND_Export.csv"
      ],
      "metadata": {
        "id": "hSxSTFAItbB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test EE connection\n",
        "print(\"EE initialized:\", ee.data._credentials)"
      ],
      "metadata": {
        "id": "smCrMc5vtgDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the base path for YOLOv8 dataset\n",
        "dataset = ee.FeatureCollection(\"users/sat-io/awesome-gee-catalog-examples\")  # Adjust to match your dataset (e.g., 'house_alloc-17')\n",
        "\n",
        "# Define all required subdirectories\n",
        "subdirs = [\n",
        "    'train/images',\n",
        "    'train/labels',\n",
        "    'valid/images',\n",
        "    'valid/labels',\n",
        "    'test/images',\n",
        "    'test/labels'\n",
        "]\n",
        "\n",
        "# Create directories\n",
        "try:\n",
        "    for subdir in subdirs:\n",
        "        dir_path = os.path.join(dataset_location, subdir)\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "    print(\"Directories for YOLOv8 dataset created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to create directories: {e}\")\n",
        "\n",
        "# Verify the structure\n",
        "print(\"Created directory structure:\")\n",
        "for subdir in subdirs:\n",
        "    print(f\"- {os.path.join(dataset_location, subdir)}\")"
      ],
      "metadata": {
        "id": "kiqfSv9_NMTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=ind,\n",
        "    description='India_FeatureCollection',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "task.start()"
      ],
      "metadata": {
        "id": "Ns48c4eHdnun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_dataset = dataset.filter(ee.Filter.eq('property_name', 'property_value'))"
      ],
      "metadata": {
        "id": "tFg0dQHjNdBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "2VlX-RKzN4It"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ3DmmGQztJj"
      },
      "outputs": [],
      "source": [
        "# Fix locale encoding\n",
        "#import locale\n",
        "#locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "# Your original code\n",
        "#dataset_location = dataset.location\n",
        "#%cat {dataset_location}/data.yaml\n",
        "\n",
        "# This is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "#dataset_location = dataset.location\n",
        "#%cat {dataset_location}/data.yaml\n",
        "\n",
        "\n",
        "# Authenticate and initialize Earth Engine\n",
        "# Add a layer to the map, using Map.addLayer:\n",
        "import folium  # If you haven't already installed it\n",
        "import ee\n",
        "\n",
        "# Initialize Folium map\n",
        "map = folium.Map(location=[20, 78], zoom_start=5)  # Adjust location/zoom as needed\n",
        "\n",
        "# Add dataset layer (GEE datasets need to be visualized differently)\n",
        "dataset = ee.FeatureCollection(\"projects/sat-io/open-datasets/VIDA_COMBINED/IND\")\n",
        "\n",
        "# Display map (this works in a Jupyter Notebook)\n",
        "display(map)\n",
        "\n",
        "# Export dataset to Google Drive\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=dataset,\n",
        "    description='awesome-gee-catalog-examples-export',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "task.start()  # This starts the export process.\n",
        "\n",
        "print(\"Export started! Check Google Drive for the file when complete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # YAML file path\n",
        "# yaml_path = os.path.join(dataset_location, 'data.yaml').replace(\"\\\\\", \"/\")\n",
        "\n",
        "# # Check if the YAML file exists\n",
        "# if os.path.exists(yaml_path):\n",
        "#     with open(yaml_path, 'r') as f:\n",
        "#         data = yaml.safe_load(f)\n",
        "# else:\n",
        "#     print(\"YAML file not found! Creating a new one...\")\n",
        "#     data = {}\n",
        "\n",
        "# # Fix relative paths\n",
        "# data['train'] = 'train/images'\n",
        "# data['val'] = 'valid/images'\n",
        "# data['test'] = 'test/images'\n",
        "# data['nc'] = 1  # Number of classes (update if needed)\n",
        "# data['names'] = ['tree']  # Class names (update accordingly)\n",
        "\n",
        "# # Write back to YAML\n",
        "# with open(yaml_path, 'w') as f:\n",
        "#     yaml.safe_dump(data, f)\n",
        "\n",
        "# # print(\"YAML file created/updated successfully!\")\n",
        "import os\n",
        "import yaml\n",
        "\n",
        "# YAML file path\n",
        "yaml_path = os.path.join(dataset_location, 'data.yaml').replace(\"\\\\\", \"/\")\n",
        "\n",
        "# Check if the YAML file exists and is not empty\n",
        "if os.path.exists(yaml_path) and os.path.getsize(yaml_path) > 0:\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        data = yaml.safe_load(f)\n",
        "    if data is None:  # Handle case where file is empty or contains invalid YAML\n",
        "        data = {}\n",
        "else:\n",
        "    print(\"YAML file not found or empty! Creating a new one...\")\n",
        "    data = {}\n",
        "\n",
        "# Fix relative paths\n",
        "data['train'] = 'train/images'\n",
        "data['val'] = 'valid/images'\n",
        "data['test'] = 'test/images'\n",
        "data['nc'] = 2  # Number of classes (update if needed)\n",
        "data['names'] = ['tree', 'building']# Class names (update accordingly)\n",
        "\n",
        "# Write back to YAML\n",
        "with open(yaml_path, 'w') as f:\n",
        "    yaml.safe_dump(data, f)\n",
        "\n",
        "print(\"YAML file created/updated successfully!\")"
      ],
      "metadata": {
        "id": "i_SMDTiAi0HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOPn9wjOAwwK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "import ee\n",
        "\n",
        "# Authenticate and initialize Google Earth Engine\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='vitproject2025')  # Replace with your actual project ID\n",
        "\n",
        "# Define dataset from Google Earth Engine\n",
        "dataset = ee.FeatureCollection(\"projects/sat-io/open-datasets/VIDA_COMBINED/IND\")\n",
        "\n",
        "# Export dataset to Google Drive\n",
        "task = ee.batch.Export.table.toDrive(\n",
        "    collection=dataset,\n",
        "    description='earth-engine-dataset-export',\n",
        "    fileFormat='CSV'\n",
        ")\n",
        "task.start()\n",
        "print(\"Google Earth Engine dataset export started. Check Google Drive for the CSV file.\")\n",
        "\n",
        "# Define the base path for YOLOv8 dataset\n",
        "base_path = '/content/earth-engine-dataset'  # Adjust for GEE dataset\n",
        "\n",
        "# Define all required subdirectories\n",
        "subdirs = [\n",
        "    'train/images',\n",
        "    'train/labels',\n",
        "    'valid/images',\n",
        "    'valid/labels',\n",
        "    'test/images',\n",
        "    'test/labels'\n",
        "]\n",
        "\n",
        "# Create directories\n",
        "try:\n",
        "    for subdir in subdirs:\n",
        "        dir_path = os.path.join(base_path, subdir)\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "    print(\"Directories for YOLOv8 dataset created successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to create directories: {e}\")\n",
        "\n",
        "# Verify the structure\n",
        "print(\"Created directory structure:\")\n",
        "for subdir in subdirs:\n",
        "    print(f\"- {os.path.join(base_path, subdir)}\")\n",
        "\n",
        "# YAML file path\n",
        "yaml_path = os.path.join(dataset_location, 'data.yaml').replace(\"\\\\\", \"/\")\n",
        "\n",
        "# Read and update the YAML\n",
        "if os.path.exists(yaml_path):\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        data = yaml.safe_load(f)\n",
        "\n",
        "    # Fix relative paths\n",
        "    data['train'] = 'train/images'\n",
        "    data['val'] = 'valid/images'\n",
        "    data['test'] = 'test/images'\n",
        "\n",
        "    # Write back\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        yaml.safe_dump(data, f)\n",
        "\n",
        "    print(\"YAML file updated successfully!\")\n",
        "else:\n",
        "    print(\"YAML file not found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = r\"/usr/local/lib/python3.11/dist-packages/ultralytics\"\n",
        "if os.path.exists(path):\n",
        "    print(os.listdir(path))\n",
        "else:\n",
        "    print(\"Path does not exist.\")"
      ],
      "metadata": {
        "id": "b5g3gkf7T21k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Rvt5wilnDyX"
      },
      "outputs": [],
      "source": [
        "# # This is the model configuration we will use for our tutorial\n",
        "# %cat /content/ultralytics/ultralytics/cfg/models/v8/yolov8-seg.yaml\n",
        "#import os\n",
        "# Path to the YOLOv8 model configuration\n",
        "#yaml_path = r\"/usr/local/lib/python3.11/dist-packages/ultralytics\"\n",
        "\n",
        "# Check if the file exists before reading\n",
        "#if os.path.exists(yaml_path):\n",
        "    #with open(yaml_path, \"r\") as file:\n",
        "        #print(file.read())\n",
        "#else:\n",
        "    #print(\"File not found:\", yaml_path)\n",
        "\n",
        "import os\n",
        "\n",
        "# Path to the YOLOv8 model configuration YAML file (updated path)\n",
        "yaml_path = r\"/usr/local/lib/python3.11/dist-packages/ultralytics/cfg/models/v8/yolov8-seg.yaml\"\n",
        "\n",
        "# Check if the file exists before reading\n",
        "if os.path.exists(yaml_path):\n",
        "    with open(yaml_path, \"r\") as file:\n",
        "        print(file.read())\n",
        "else:\n",
        "    print(\"File not found:\", yaml_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t14hhyqdmw6O"
      },
      "outputs": [],
      "source": [
        "# Register the custom writetemplate magic\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify your inference code (last cell):\n",
        "\n",
        "# Define colors for classes\n",
        "class_colors = {\n",
        "    0: (0, 255, 0),  # Green for trees\n",
        "    1: (0, 0, 255)   # Blue for buildings\n",
        "}\n",
        "\n",
        "for r in results:\n",
        "    im_array = r.plot(\n",
        "        labels=True,\n",
        "        masks=True,  # <--- Enable mask visualization\n",
        "        conf=True,\n",
        "        boxes=True,\n",
        "        line_width=1,\n",
        "        font_size=10,\n",
        "        pil=True,\n",
        "        kpt_line=True,\n",
        "        labels=False,\n",
        "        probs=True,\n",
        "        colors=class_colors  # <--- Apply custom colors\n",
        "    )\n",
        "\n",
        "    # Rest of your saving/display code remains the same"
      ],
      "metadata": {
        "id": "JMso0M2mri-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDxebz13RdRA"
      },
      "outputs": [],
      "source": [
        "# Set number of classes\n",
        "num_classes = 1  # For 'Houses' from house_alloc-17\n",
        "\n",
        "# Write YOLOv8m custom config using Python file I/O\n",
        "config_text = f\"\"\"# YOLOv8 medium custom config\n",
        "nc: {num_classes}  # Number of classes (1 for Houses)\n",
        "depth_multiple: 0.67  # Model depth multiple (medium scale)\n",
        "width_multiple: 0.75  # Layer channel multiple (medium scale)\n",
        "\n",
        "# Backbone\n",
        "backbone:\n",
        "  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2\n",
        "  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4\n",
        "  - [-1, 3, C2f, [128, True]]   # 2\n",
        "  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8\n",
        "  - [-1, 6, C2f, [256, True]]   # 4\n",
        "  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16\n",
        "  - [-1, 6, C2f, [512, True]]   # 6\n",
        "  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\n",
        "  - [-1, 3, C2f, [1024, True]]  # 8\n",
        "  - [-1, 1, SPPF, [1024, 5]]    # 9 (SPP block)\n",
        "\n",
        "# Head\n",
        "head:\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]  # 10\n",
        "  - [[-1, 6], 1, Concat, [1]]  # 11 cat backbone P4\n",
        "  - [-1, 3, C2f, [512, True]]   # 12\n",
        "  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]  # 13\n",
        "  - [[-1, 4], 1, Concat, [1]]  # 14 cat backbone P3\n",
        "  - [-1, 3, C2f, [256, True]]   # 15 (P3/8-small)\n",
        "  - [-1, 1, Conv, [256, 3, 2]]  # 16\n",
        "  - [[-1, 12], 1, Concat, [1]]  # 17 cat head P4\n",
        "  - [-1, 3, C2f, [512, True]]   # 18 (P4/16-medium)\n",
        "  - [-1, 1, Conv, [512, 3, 2]]  # 19\n",
        "  - [[-1, 9], 1, Concat, [1]]  # 20 cat head P5\n",
        "  - [-1, 3, C2f, [1024, True]]  # 21 (P5/32-large)\n",
        "  - [[15, 18, 21], 1, Detect, [nc]]  # Detect(P3, P4, P5)\n",
        "\"\"\"\n",
        "\n",
        "# Save the config file\n",
        "config_path = \"/content/yolov8m-custom.yaml\"\n",
        "with open(config_path, \"w\") as f:\n",
        "    f.write(config_text)\n",
        "\n",
        "print(f\"Config file saved at {config_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSPQthWMMzjI"
      },
      "outputs": [],
      "source": [
        "# # Update the Ultralytics repo for YOLOv8\n",
        "# !cd /content/ultralytics && git pull\n",
        "\n",
        "import os\n",
        "\n",
        "repo_path = r\"C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\ultralytics\"\n",
        "\n",
        "os.system(f'cd /d \"{repo_path}\" && git pull')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_location)"
      ],
      "metadata": {
        "id": "O4QBS5ZOX0jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
      ],
      "metadata": {
        "id": "vjCSEw1s0Pua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "dataset_location = base_path # points to /content/earth-engine-dataset"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "O-jCEUrd22mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import ee\n",
        "import os\n",
        "import folium\n",
        "import time\n",
        "\n",
        "# Authenticate and initialize Earth Engine\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='vitproject2025')  # Replace with your project ID\n",
        "\n",
        "# Load the dataset and limit it to 5 features (for testing, you can increase later)\n",
        "dataset = ee.FeatureCollection(\"projects/sat-io/open-datasets/VIDA_COMBINED/IND\") \\\n",
        "    .filter(ee.Filter.inList('class', ['tree', 'building']))\n",
        "# Define the base path for YOLOv8 dataset\n",
        "base_path = '/content/earth-engine-dataset'  # Local folder\n",
        "\n",
        "# Create directories for the dataset\n",
        "os.makedirs(os.path.join(base_path, 'images'), exist_ok=True)\n",
        "\n",
        "# Function to download an image\n",
        "def download_image(feature):\n",
        "    image_id = feature.get('system:index').getInfo()  # Assuming image ID is stored in 'system:index' property\n",
        "    image = ee.Image(feature.get('B4'))  # Replace 'B4' with the actual band property\n",
        "\n",
        "    # Start the export task\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=image,\n",
        "        description=f'image_{image_id}',\n",
        "        folder='earth-engine-dataset/images',  # Google Drive folder\n",
        "        region=feature.geometry(),\n",
        "        scale=30  # Adjust scale as needed\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "    # Wait for the task to complete (polling)\n",
        "    timeout = time.time() + 60  # 5-minute timeout\n",
        "    while task.active():\n",
        "        print(f\"Downloading {image_id}... Please wait.\")\n",
        "        time.sleep(10)  # Sleep for 10 seconds before checking again\n",
        "\n",
        "        # Check for timeout\n",
        "        if time.time() > timeout:\n",
        "            print(f\"Download for {image_id} timed out.\")\n",
        "            # Instead of stopping the task (which is not supported),\n",
        "            # you can just break out of the loop and continue with the next feature.\n",
        "            print(\"Task will continue in the background. Proceeding to the next feature.\")\n",
        "            break\n",
        "\n",
        "    # Once the task is finished or timed out, print the status\n",
        "    if task.active():\n",
        "        print(f\"Download complete for image: {image_id}\")\n",
        "    else:\n",
        "        print(f\"Task for image {image_id} has been stopped or timed out.\")\n",
        "\n",
        "# Iterate and download images\n",
        "dataset_size = dataset.size().getInfo()\n",
        "for i in range(dataset_size):\n",
        "    feature = ee.Feature(dataset.toList(dataset_size).get(i))\n",
        "    download_image(feature)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "u3MuFWLD25CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train: \"/content/earth-engine-dataset/train/images\"  # Correct path for training images\n",
        "val: \"/content/earth-engine-dataset/valid/images\"  # Correct path for validation images\n",
        "nc: 80  # Number of classes (adjust as needed)\n",
        "names: ['class1', 'class2', ...]  # List of class names\n",
        "names: ['class1', 'class2', ...]  # List of class names\n"
      ],
      "metadata": {
        "id": "Tl9wLSZz9yOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train: \"/content/earth-engine-dataset/images/train\"  # Adjust to your actual path\n",
        "val: \"/content/earth-engine-dataset/images/valid\"  # Adjust to your actual path"
      ],
      "metadata": {
        "id": "euweDDbH94vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n",
        "!pip install earthengine-api\n",
        "!pip install folium\n",
        "\n",
        "import ee\n",
        "import os\n",
        "import folium\n",
        "import time\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image  # Import the PIL library\n",
        "\n",
        "# Authenticate and initialize Earth Engine\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='vitproject2025')  # Replace with your project ID\n",
        "\n",
        "# Load the dataset and limit it to 5 features (for testing, increase later)\n",
        "dataset = ee.FeatureCollection(\"projects/sat-io/open-datasets/VIDA_COMBINED/IND\").limit(5)\n",
        "\n",
        "# Define the base path for YOLOv8 dataset\n",
        "base_path = '/content/earth-engine-dataset'  # Local folder\n",
        "\n",
        "# Create directories for the dataset\n",
        "subdirs = [\n",
        "    # Modify class numbers in your dataset preparation:\n",
        "subdirs = [\n",
        "    'train/images',\n",
        "    'train/labels',\n",
        "    'train/masks',  # <--- Add masks directory for segmentation\n",
        "    'valid/images',\n",
        "    'valid/labels',\n",
        "    'valid/masks',\n",
        "]\n",
        "]\n",
        "for subdir in subdirs:\n",
        "    os.makedirs(os.path.join(base_path, subdir), exist_ok=True)\n",
        "\n",
        "# Function to download and convert an image to JPG\n",
        "def download_image(feature, split='train'):\n",
        "    image_id = feature.get('system:index').getInfo()\n",
        "    image = ee.Image(feature.get('B4'))  # Replace 'B4' with the actual band property\n",
        "\n",
        "    # Start the export task to Drive (GeoTIFF format)\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=image,\n",
        "        description=f'image_{image_id}',\n",
        "        folder=os.path.join('earth-engine-dataset', 'images', split),  # Google Drive folder\n",
        "        region=feature.geometry(),\n",
        "        scale=30,  # Adjust scale as needed\n",
        "        fileFormat='GeoTIFF'\n",
        "    )\n",
        "    task.start()\n",
        "\n",
        "    # Wait for the task to complete (polling) with a longer timeout\n",
        "    timeout = time.time() + 300  # Wait for 5 minutes\n",
        "    while task.active():\n",
        "        print(f\"Downloading {image_id}... Please wait.\")\n",
        "        time.sleep(10)\n",
        "        if time.time() > timeout:\n",
        "            print(f\"Download for {image_id} timed out.\")\n",
        "            print(\"Task will continue in the background. Proceeding to the next feature.\")\n",
        "            break\n",
        "\n",
        "    # If download was successful, convert to JPG\n",
        "    if not task.active():\n",
        "        print(f\"Download complete for image: {image_id}\")\n",
        "        # Assuming images are downloaded to 'MyDrive'\n",
        "        tif_path = os.path.join('/content/drive/MyDrive/earth-engine-dataset/images', split, f'image_{image_id}.tif')\n",
        "\n",
        "        # Convert TIF to JPG using PIL\n",
        "        try:\n",
        "            im = Image.open(tif_path)\n",
        "            jpg_path = os.path.join(base_path, 'images', split, f'image_{image_id}.jpg')\n",
        "            im.convert('RGB').save(jpg_path)\n",
        "            print(f\"Converted {tif_path} to {jpg_path}\")\n",
        "            os.remove(tif_path)  # Delete the original TIF\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting TIF to JPG: {e}\")\n",
        "    else:\n",
        "        print(f\"Task for image {image_id} has been stopped or timed out.\")\n",
        "\n",
        "\n",
        "# Iterate and download images (example with train/valid split)\n",
        "dataset_size = dataset.size().getInfo()\n",
        "for i in range(dataset_size):\n",
        "    feature = ee.Feature(dataset.toList(dataset_size).get(i))\n",
        "    if i < int(dataset_size * 0.8):\n",
        "        download_image(feature, split='train')\n",
        "    else:\n",
        "        download_image(feature, split='valid')\n",
        "\n",
        "# Create/Update data.yaml with full paths\n",
        "data_yaml_path = os.path.join(base_path, 'data.yaml')\n",
        "data = {}\n",
        "data['train'] = os.path.join(base_path, 'images/train')  # Full path to training images\n",
        "data['val'] = os.path.join(base_path, 'images/valid')   # Full path to validation images\n",
        "data['test'] = os.path.join(base_path, 'images/test')   # Full path to test images (if any)\n",
        "data['nc'] = 1  # Number of classes (1 for 'tree')\n",
        "data['names'] = ['tree']  # Class names\n",
        "\n",
        "with open(data_yaml_path, 'w') as f:\n",
        "    yaml.safe_dump(data, f)\n",
        "print(f\"data.yaml created/updated at {data_yaml_path}\")\n",
        "\n",
        "# Load pretrained YOLOv8n model\n",
        "model = YOLO(\"yolov8m-custom.yaml\").load(\"yolov8m.pt\")  # Load with pre-trained weights\n",
        "\n",
        "# Train the model\n",
        "model.train(\n",
        "    data=data_yaml_path,\n",
        "    epochs=5,\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    task='segment',  # <--- Add this line\n",
        "    name=\"yolov8m_seg_results\",\n",
        "    patience=2,\n",
        "    cache=\"disk\",\n",
        "    device=0,\n",
        "    workers=4,\n",
        "    pretrained=True,\n",
        "    lr0=0.0005,\n",
        "    mosaic=1.0,\n",
        "    augment=True,\n",
        "    name=\"yolov8m_results_80\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "img_path = list(uploaded.keys())[0]  # Get the uploaded file name\n",
        "print(\"Using file:\", img_path)\n"
      ],
      "metadata": {
        "id": "ALwqEUEhVaeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load TIF image using PIL\n",
        "image = Image.open(img_path).convert(\"RGB\")  # Convert to RGB\n",
        "\n",
        "# Convert to numpy array (YOLO expects numpy format)\n",
        "image_np = np.array(image)\n",
        "\n",
        "# Load trained YOLO model\n",
        "model = YOLO(\"runs/detect/yolov8m_results_80/weights/best.pt\")\n",
        "\n",
        "# Run inference\n",
        "results = model(image_np)\n",
        "\n",
        "# Define output directory inside Colab\n",
        "output_dir = \"/content/output\"\n",
        "os.makedirs(output_dir, exist_ok=True)  # Create folder if it doesn't exist\n",
        "\n",
        "# Extract original filename without extension\n",
        "base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "output_path = os.path.join(output_dir, f\"{base_name}_output.jpg\")\n",
        "\n",
        "# Display and save results\n",
        "for r in results:\n",
        "    im_array = r.plot(labels=False)  # Get the result image\n",
        "\n",
        "    # Convert array to PIL Image\n",
        "    result_image = Image.fromarray(im_array)\n",
        "\n",
        "    # Save with quality settings (JPEG format)\n",
        "    result_image.save(output_path, format=\"JPEG\", quality=95)\n",
        "\n",
        "    # Show the processed image\n",
        "    plt.imshow(result_image)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Result saved at {output_path}\")\n",
        "\n",
        "# Download the image to your local machine\n",
        "files.download(output_path)\n"
      ],
      "metadata": {
        "id": "Ab-PK1fZXfZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Metrics"
      ],
      "metadata": {
        "id": "O7gjjJlVfeXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Path to your image file\n",
        "img_path1 = '/content/runs/detect/yolov8m_results_80/results.png'\n",
        "\n",
        "# Display the image\n",
        "Image(filename=img_path1)\n",
        "\n"
      ],
      "metadata": {
        "id": "IfvOD3W6zczU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVs_4zEeVbF"
      },
      "source": [
        "# Evaluate Custom YOLOv8 Detector Performance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov8s_results_80`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
        "\n",
        "Note from Glenn: Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOy5KI2ncnWd"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SyOWS80qR32"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}